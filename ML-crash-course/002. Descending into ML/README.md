# 선형 회귀(Linear Regression)

## 선형 관계
`y = mx + b`

- `y` : 예측하려는 값
- `m` : 직선의 기울기
- `x` : 입력 특성 값
- `b` : y절편

-> 모델의 방정식을 작성:

`y = b + w1 * x1`

- `y` : 예측된 라벨 -> 얻고자 하는 출력
- `b` : 편향(y절편)
- `w1` : 특성 1의 가중치
- `x1` : 특성 1 -> 알려진 입력

모델에 `x1` 값을 삽입 -> `x1`에서 `y`를 추론(예측)할 수 있음

아래첨자 : 여러 특성에 의존하는 좀 더 정교한 모델을 예시함

# 학습 및 손실(Training and Loss)

## 학습
라벨이 있는 데이터 -> 올바른 가중치와 편향값을 결정

### 경험적 위험 최소화
지도 학습에서 다양한 예를 검토하고 손실을 최소화하는 모델을 찾아 만들어내는 과정

## 손실
한 가지 예에서 모델의 예측이 얼마나 잘못되었는지를 나타내는 수(예측이 완벽할 때 0)

### 모델 학습의 목표
모든 예에서 평균적으로 작은 손실을 가지는 가중치, 편향의 집합을 찾는 것

## 손실 함수
유의미한 방식으로 개별 손실을 종합

### 제곱 손실
```python
(observation - prediction(x)) ** 2
```

라벨과 예측 간 차의 제곱

### 평균 제곱 오차(MSE)
MSE : 예시당 평균 제곱 손실 -> `(개별 예의 모든 손실의 합)/(예의 수)`

- 머신러닝에서 흔히 사용되나 모든 상황에서 최선인 유일한 손실 함수는 아님
